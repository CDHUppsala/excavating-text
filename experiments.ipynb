{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab51068a-7972-4127-b8f6-49edb495aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForTokenClassification, BertTokenizer\n",
    "from transformers import AutoModelForTokenClassification, Trainer, AutoTokenizer, DataCollatorForTokenClassification, TrainingArguments, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3af4c45-8f36-4e96-9061-11a74893c407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path:  /home/adam/code/bertbased/kbtraining/checkpoint-10000/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_list=[\"O\", \"B-HUSTYP\", \"B-KONSTRUKTIONSDETALJ\", \"B-LST_DNR\", \"B-SR_SYSTEM\", \"B-SR_KOORDINATER\", \"B-INTRASIS\", \"I-HUSTYP\", \"I-KONSTRUKTIONSDETALJ\", \"I-LST_DNR\", \"I-SR_SYSTEM\", \"I-SR_KOORDINATER\", \"I-INTRASIS\"]\n",
    "main_path = \"/home/adam/code/bertbased/kbtraining/checkpoint-10000/\"\n",
    "# Step 1: Load pre-trained model and tokenizer\n",
    "model_path = main_path + \"model.safetensors\"\n",
    "tokenizer_path = main_path + \"tokenizer.json\"\n",
    "print(\"model path: \", model_path)\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(main_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(main_path)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Load additional files if required (config, optimizer, scheduler, etc.)\n",
    "config_path = main_path + \"config.json\"\n",
    "optimizer_path = main_path +\"optimizer.pt\"\n",
    "scheduler_path = main_path + \"scheduler.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a30bdd1-bb76-4333-b27a-26b1bcf6f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load config (if needed)\n",
    "# config = BertConfig.from_json_file(config_path)\n",
    "\n",
    "# Load optimizer and scheduler states (if needed)\n",
    "# optimizer_state = torch.load(optimizer_path)\n",
    "# scheduler_state = torch.load(scheduler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460388af-88d0-47de-8676-5d45790cc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform inference or testing\n",
    "# Example input text\n",
    "input_text = \"Utredningen har utförts enligt beslut av Länsstyrelsen i Västra Götalands\\nlän (dnr 220-39195-99) och har bekostats av Alvereds golf. Länsstyrelsens dnr: 220-39195-99. Koordinater för undersökningsytans sydvästra hörn:\\nx 6395,00  y 1272,25y.\"\n",
    "#input_text =\"Böndernas hus.\"\n",
    "# Tokenize input text\n",
    "tokens = tokenizer.tokenize(input_text)\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_ids = tokenizer.build_inputs_with_special_tokens(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ff6ecb-560a-4d01-bc47-bbcf9343af64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: Utredningen har utförts enligt beslut av Länsstyrelsen i Västra Götalands\n",
      "län (dnr 220-39195-99) och har bekostats av Alvereds golf. Länsstyrelsens dnr: 220-39195-99. Koordinater för undersökningsytans sydvästra hörn:\n",
      "x 6395,00  y 1272,25y.\n",
      "Result ['O', 'O', 'O', 'O', 'O', 'O', 'B-LST_DNR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-SR_KOORDINATER', 'I-SR_KOORDINATER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(torch.tensor([input_ids]))\n",
    "\n",
    "# Get predicted labels\n",
    "predicted_labels = torch.argmax(outputs.logits, dim=2).squeeze()\n",
    "\n",
    "# Decode labels\n",
    "decoded_labels = [tokenizer.decode([label]) for label in predicted_labels]\n",
    "res_labels = [label_list[label] for label in predicted_labels]\n",
    "\n",
    "# Display results\n",
    "print(\"Input Text:\", input_text)\n",
    "print(\"Result\", res_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c3e68ce-d2ea-45c3-97df-479da979c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "nlp =  pipeline('ner', model=main_path, tokenizer=main_path)\n",
    "res = nlp(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc9f4dd-e11c-4e17-ae26-3f4bdfe7e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    f'LABEL_{i+1}': label_list[i] for i in range(len(label_list))\n",
    "}\n",
    "for item in res:\n",
    "    if 'entity' in item and item['entity'] in label_mapping:\n",
    "        item['entity'] = label_mapping[item['entity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df3bfb46-90c0-4217-af19-d471f6dcda23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-KONSTRUKTIONSDETALJ',\n",
       "  'score': 0.5757647,\n",
       "  'index': 6,\n",
       "  'word': 'av',\n",
       "  'start': 38,\n",
       "  'end': 40},\n",
       " {'entity': 'B-SR_SYSTEM',\n",
       "  'score': 0.9816751,\n",
       "  'index': 47,\n",
       "  'word': 'undersöknings',\n",
       "  'start': 183,\n",
       "  'end': 196},\n",
       " {'entity': 'I-SR_SYSTEM',\n",
       "  'score': 0.9325778,\n",
       "  'index': 48,\n",
       "  'word': '##ytan',\n",
       "  'start': 196,\n",
       "  'end': 200}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[obj for obj in res if obj['entity'] != 'LABEL_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b173f-7a3b-4166-af5f-07a5816387d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
